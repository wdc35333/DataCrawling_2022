{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e67b8c3",
   "metadata": {},
   "source": [
    "### Open CV 이해\n",
    "- OpenCV (Open Source Computer Vision)은 오픈소스 컴퓨터 비전 라이브러리\n",
    "- OpenCV는 단일 이미지나 동영상의 이미지를 원하는 결과를 분석 및 추출하기 위한 API\n",
    "- 객체 얼굴 행동 인식, 독순, 모션 추적 등의 응용 프로그램에서 사용\n",
    "- 사이트: https://docs.opencv.org/4.2.0/d1/dfb/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1143592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e953c5f8",
   "metadata": {},
   "source": [
    "## Open CV를 이용한 웹캠 연결 및 화면 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용중인 PC에 연결된 0번째 웹캠 또는 카메라 영상 연결\n",
    "cap_img = cv2.VideoCapture(0)\n",
    "\n",
    "# 카메라 속성 설정(화면 크기: 가로 640, 세로 480)\n",
    "cap_img.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap_img.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# 영상 출력\n",
    "while True:\n",
    "    ret, frame = cap_img.read() # 카메라의 상태 및 프레임을 읽어옴\n",
    "                                # ret: 카메라 작동 상태(True/False)\n",
    "    # cv2.imshow를 이용해 출력\n",
    "    cv2.imshow('VideoFrame', frame)\n",
    "    \n",
    "    # 키보드의 아무키나 누르면 종료\n",
    "    if cv2.waitKey(1) > 0: break\n",
    "        \n",
    "# 카메라 장치에서 받아온 메모리 해제        \n",
    "cap_img.release()    \n",
    "# 윈도우 창 닫기()\n",
    "cv2.destroyAllWindows() \n",
    "# 특정 창 닫기: cv2.destroyWindow(\"윈도우 창 제목\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d763277",
   "metadata": {},
   "source": [
    "## 카메라 영상을 파일로 저장\n",
    "\n",
    "- XVID 코덱 사용()\n",
    "- 파일의 확장자 mp4, avi 등 코덱이 지원하는 형식 사용\n",
    "- 파일명(\"out_video_1.mp4\"), 프레임률(20,0), 영상크기(640*480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0e539c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cap=cv2.VideoCapture(0)  \n",
    "\n",
    "# XVID 코덱 사용\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "# 파일명, 프레임률(20.0) 영상크기 (640*480) 지정\n",
    "out_cap=cv2.VideoWriter(\"./data/out_video_1.mp4\", fourcc, 20.0, (640, 480))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        frame = cv2.flip(frame, 1) # 1은 좌우 반전, 0은 상하 반전입니다.\n",
    "        \n",
    "        out_cap.write(frame)    # 영상 저장\n",
    "        cv2.imshow(\"Save_Frame\", frame)\n",
    "        if cv2.waitKey(1) > 0 : break\n",
    "    else:\n",
    "        print(\"캠을 켜주세요\")\n",
    "        break\n",
    "        \n",
    "cap.release()             # 캠 종료\n",
    "out_cap.release()         # 저장 종료\n",
    "cv2.destroyAllWindows()   # 창 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6856d0d0",
   "metadata": {},
   "source": [
    "## 웹캠에서 사람 얼굴 인지하기\n",
    "- 데이터: https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab556b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13771190",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_case = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640) # 너비\n",
    "cap.set(3, 480) # 높이\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1) # 좌우 대칭\n",
    "    faces = face_case.detectMultiScale(frame,\n",
    "                                      scaleFactor = 1.05,  # 이미지에서 얼굴 크기가 서로 다를 것을 보정해주는 값\n",
    "                                      minNeighbors = 5 # 얼굴 사이의 최소 간격(픽셀 단위)\n",
    "                                      )\n",
    "    if len(faces):\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h) , (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow('faces', frame)\n",
    "    if cv2.waitKey(24) == 27: break # ESC 키 입력시 종료\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
